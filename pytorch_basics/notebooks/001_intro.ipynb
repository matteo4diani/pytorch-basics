{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 462,
   "id": "16fbf5ee-39c8-467e-a8d4-1a7b9a8f7518",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "id": "e12caef2-dac9-46a4-a352-3fd96b8cf9a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.], device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "if torch.backends.mps.is_available():\n",
    "    mps_device = torch.set_default_device(\"mps\")\n",
    "    x = torch.ones(1, device=mps_device)\n",
    "    print (x)\n",
    "else:\n",
    "    print (\"MPS device not found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "747e6267-0758-4b8a-802c-b4aa3957a998",
   "metadata": {},
   "source": [
    "# Creating Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "id": "aa5d4c88-8125-4400-8b10-abe9227dea81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7, device='mps:0')"
      ]
     },
     "execution_count": 464,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scalar\n",
    "\n",
    "scalar = torch.tensor(7)\n",
    "scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "id": "2c9d1524-723a-40d7-8406-14dbc75142c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 465,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "id": "172084bd-62fa-4a55-858b-a9f6e95c4e79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 466,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar.item() # Get POPO back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "id": "5b571bc8-f0ad-4922-8332-86548d82d8f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7, 7], device='mps:0')"
      ]
     },
     "execution_count": 467,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vector\n",
    "\n",
    "vector = torch.tensor([7, 7])\n",
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "id": "2dcef92e-82e3-4a11-bcf2-602f4f8b4f86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 468,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector.ndim # Dimension of the tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "id": "dbcd8c50-cc9f-4cc2-9ba5-3491e88fdc9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2])"
      ]
     },
     "execution_count": 469,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector.shape # Shape of the tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "id": "3c3a556b-1e33-4b80-a40a-f4a6572a471d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 7,  8],\n",
       "        [ 9, 10]], device='mps:0')"
      ]
     },
     "execution_count": 470,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MATRIX\n",
    "\n",
    "matrix = torch.tensor(\n",
    "    [[7, 8],\n",
    "     [9, 10]]\n",
    ")\n",
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "id": "9d715800-e8c7-48da-8ccc-4e12d3b03f13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 471,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "id": "e8a966d4-ef7c-4e19-8e28-31ab5bb8b11e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7, 8], device='mps:0')"
      ]
     },
     "execution_count": 472,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "id": "c34b0b09-df1d-489a-9c56-ea669d4ff71e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2])"
      ]
     },
     "execution_count": 473,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "id": "ae507133-a07a-4436-8d1c-0c2edd57553b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 2, 3],\n",
       "         [4, 5, 6],\n",
       "         [7, 8, 9]]], device='mps:0')"
      ]
     },
     "execution_count": 474,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TENSOR\n",
    "\n",
    "tensor = torch.tensor(\n",
    "    [[[1, 2, 3],\n",
    "      [4, 5, 6],\n",
    "      [7, 8, 9]]]\n",
    ")\n",
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "id": "ff01e33f-4fbf-441c-bf96-5d5fd0cd0a97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [4, 5, 6],\n",
       "        [7, 8, 9]], device='mps:0')"
      ]
     },
     "execution_count": 475,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "id": "ffb377b8-7efb-46fa-85fd-996d6730854d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3], device='mps:0')"
      ]
     },
     "execution_count": 476,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor[0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "id": "9c3e5485-66f3-405d-bc9f-b8231e4eba71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7, 8, 9], device='mps:0')"
      ]
     },
     "execution_count": 477,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor[0, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "id": "dbdc636e-2152-4aee-a478-f3d6e1fe3163",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 478,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "id": "687b6829-0fd3-4c99-9e2c-d6beae19c3cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 3])"
      ]
     },
     "execution_count": 479,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d20c27e-d682-4e0f-8c08-d7300a4a9c7e",
   "metadata": {},
   "source": [
    "## Random Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "id": "85f4b018-2e5b-4e5e-8f64-7e287f105161",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4237, 0.8227, 0.5083, 0.1392],\n",
       "        [0.6552, 0.8493, 0.8293, 0.5814],\n",
       "        [0.1388, 0.4395, 0.2429, 0.1631]], device='mps:0')"
      ]
     },
     "execution_count": 480,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random Tensor\n",
    "random_tensor = torch.rand(3, 4)\n",
    "random_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "id": "11798346-a124-4ad2-8921-fe48013b4ba9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 481,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_tensor.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "id": "4ea4723d-7d01-4b2b-9844-30948343d845",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 4])"
      ]
     },
     "execution_count": 482,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "id": "40dcb926-5e36-4368-8ca1-2e5fe2d70397",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0034, 0.8921, 0.1979]], device='mps:0')"
      ]
     },
     "execution_count": 483,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_tensor = torch.rand(1, 3)\n",
    "random_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "id": "f400f6ba-952a-48f6-9a15-af2ee3d7ef7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9224],\n",
       "        [0.5510],\n",
       "        [0.8471]], device='mps:0')"
      ]
     },
     "execution_count": 484,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_tensor = torch.rand(3, 1)\n",
    "random_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "id": "dbc47ca3-0ea1-46fb-b98d-d6ebf8a1c8ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.5580, 0.0894, 0.4500], device='mps:0')"
      ]
     },
     "execution_count": 485,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_tensor = torch.rand(3)\n",
    "random_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "id": "c6582c65-96d6-4053-94d9-cb69b1107a51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8719336986541748"
      ]
     },
     "execution_count": 486,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_tensor = torch.rand(1)\n",
    "random_tensor.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "id": "6aa37e16-541f-42ec-822c-305381c46e7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[2.5258e-01, 2.2121e-01, 8.9705e-01],\n",
       "         [2.8522e-01, 8.4419e-01, 9.1704e-01],\n",
       "         [5.2319e-01, 3.9663e-01, 9.8782e-01],\n",
       "         ...,\n",
       "         [4.4973e-02, 6.7166e-01, 3.0455e-01],\n",
       "         [7.4906e-01, 9.3800e-01, 7.4593e-02],\n",
       "         [5.8828e-02, 8.9117e-01, 5.4684e-01]],\n",
       "\n",
       "        [[2.3437e-01, 6.0155e-01, 8.5091e-01],\n",
       "         [3.2665e-01, 3.0527e-01, 9.3747e-01],\n",
       "         [3.0045e-01, 9.9311e-01, 1.4619e-01],\n",
       "         ...,\n",
       "         [2.2426e-01, 7.7095e-01, 9.1538e-01],\n",
       "         [2.5917e-01, 2.9984e-01, 4.5368e-02],\n",
       "         [6.5765e-01, 9.3258e-01, 5.4022e-01]],\n",
       "\n",
       "        [[2.7642e-01, 9.5002e-01, 6.0580e-01],\n",
       "         [5.8911e-01, 7.4367e-01, 8.4252e-01],\n",
       "         [4.8683e-01, 6.6565e-01, 6.6882e-01],\n",
       "         ...,\n",
       "         [1.2833e-01, 4.0233e-01, 6.4158e-04],\n",
       "         [5.3415e-01, 8.0812e-01, 1.4957e-01],\n",
       "         [5.5598e-02, 4.9739e-01, 6.8434e-01]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[6.9403e-01, 9.7248e-01, 6.8334e-01],\n",
       "         [2.5618e-01, 3.4078e-02, 3.3683e-01],\n",
       "         [6.5557e-01, 3.1887e-01, 9.5153e-01],\n",
       "         ...,\n",
       "         [2.8683e-01, 6.8557e-01, 7.6564e-01],\n",
       "         [8.2997e-01, 2.4829e-01, 3.5238e-01],\n",
       "         [7.8082e-01, 5.7893e-01, 2.8505e-01]],\n",
       "\n",
       "        [[5.2470e-01, 8.2350e-02, 2.4714e-01],\n",
       "         [1.8031e-01, 9.4118e-01, 5.8910e-02],\n",
       "         [2.4008e-01, 9.5669e-01, 4.9326e-01],\n",
       "         ...,\n",
       "         [4.0654e-01, 7.9777e-02, 3.4735e-01],\n",
       "         [2.2006e-01, 2.0870e-01, 4.5941e-01],\n",
       "         [4.2819e-01, 7.5294e-01, 6.8788e-01]],\n",
       "\n",
       "        [[3.0591e-01, 1.2213e-01, 7.9260e-01],\n",
       "         [9.2922e-01, 8.6711e-01, 8.0134e-01],\n",
       "         [4.1227e-01, 3.7344e-02, 7.9663e-01],\n",
       "         ...,\n",
       "         [8.6271e-01, 8.3727e-01, 4.2155e-01],\n",
       "         [6.7704e-01, 4.5051e-01, 7.3598e-01],\n",
       "         [1.0300e-01, 8.2889e-01, 8.2930e-01]]], device='mps:0')"
      ]
     },
     "execution_count": 487,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random Tensor with same shape as image tensor\n",
    "# height, width, colour channels (R, G, B) \n",
    "random_image_size_tensor = torch.rand(size=(224, 224, 3))\n",
    "random_image_size_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "id": "b06815e6-35eb-42a3-b491-589c9b510b1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5210, 0.8993, 0.9397, 0.3199],\n",
      "        [0.1792, 0.4677, 0.3284, 0.2487],\n",
      "        [0.1626, 0.4897, 0.3213, 0.7190]], device='mps:0')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 488,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random Tensor of 0 and 1\n",
    "random_tensor = torch.rand(3, 4)\n",
    "zeros = torch.zeros(random_tensor[0].shape)\n",
    "print(random_tensor)\n",
    "zeros.dot(random_tensor).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "id": "cfc44d03-d426-4d14-98b2-3e3e608e7f4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6384, 0.9395, 0.0212, 0.3326],\n",
      "        [0.4436, 0.2475, 0.2852, 0.7124],\n",
      "        [0.9190, 0.6330, 0.9726, 0.7432]], device='mps:0')\n",
      "tensor(6.8884, device='mps:0')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(6.8884, device='mps:0')"
      ]
     },
     "execution_count": 489,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random Tensor of 0 and 1\n",
    "random_tensor = torch.rand(3, 4)\n",
    "ones = torch.ones(random_tensor[0].shape)\n",
    "print(random_tensor)\n",
    "print(ones.dot(random_tensor)) # sum of all elements\n",
    "random_tensor.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "id": "4e7f53d7-da83-444f-8331-10cff991dc31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 490,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ones.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "id": "4fc36c62-e8d4-4c79-96dc-8ea643136550",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 491,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zeros.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c528814-ce9b-4af7-9d11-89f3debd23dc",
   "metadata": {},
   "source": [
    "## Creating tensors from fixed ranges and other tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "id": "3b44b15d-900b-43c2-916a-cf05a6144cc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], device='mps:0')"
      ]
     },
     "execution_count": 492,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(0, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "id": "469cf469-cce4-443e-8a90-6f9d0f4618a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  0,  77, 154, 231, 308, 385, 462, 539, 616, 693, 770, 847, 924],\n",
       "       device='mps:0')"
      ]
     },
     "execution_count": 493,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(start=0, end=1000, step=77)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "id": "66eb222d-97f4-4cd9-9236-c63c2e968f37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='mps:0')"
      ]
     },
     "execution_count": 494,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Copy tensor\n",
    "one_to_ten = torch.arange(start=1, end=11, step=1)\n",
    "ten_zeros = torch.zeros_like(one_to_ten)\n",
    "ten_zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "id": "014fdb99-d5fe-4a80-99bd-7945d7e88518",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3., 6., 9.], device='mps:0')"
      ]
     },
     "execution_count": 495,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float32_tensor = torch.tensor([3.0, 6.0, 9.0], dtype=None)\n",
    "float32_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "id": "2d387b63-5fe8-45b2-9524-fec7f973aba7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 496,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float32_tensor.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "id": "83e337e4-00d4-4223-ae12-155794e5ba54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3., 6., 9.], device='mps:0', dtype=torch.float16)"
      ]
     },
     "execution_count": 497,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float16_tensor = torch.tensor([3.0, 6.0, 9.0], dtype=torch.float16)\n",
    "float16_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "id": "dd512cb4-7059-4fcb-a7aa-406c0ba99dfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float16"
      ]
     },
     "execution_count": 498,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float16_tensor.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "id": "3144e088-a936-4543-af0a-7adec518736d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int64"
      ]
     },
     "execution_count": 499,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int64_tensor = torch.tensor([3, 6, 9], dtype=None)\n",
    "int64_tensor.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "id": "f49110ad-3f48-42da-95fe-c57ce9767d0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3., 6., 9.])"
      ]
     },
     "execution_count": 500,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cpu_tensor = torch.tensor([3.0, 6.0, 9.0], device=\"cpu\")\n",
    "cpu_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "id": "c3a824b6-10bc-4487-9c45-89bce125a2bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3., 6., 9.], device='mps:0')"
      ]
     },
     "execution_count": 501,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nograd_tensor = torch.tensor([3.0, 6.0, 9.0], requires_grad=False)\n",
    "nograd_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c6f0ff-4a9d-4a80-bc83-9879df254590",
   "metadata": {},
   "source": [
    "# Tensor Datatypes\n",
    "\n",
    "3 common pitfalls:\n",
    "\n",
    "1. Tensors not right datatype\n",
    "2. Tensors not right shape\n",
    "3. Tensors not on the right device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "id": "abbe99f7-5ee3-48c1-8b95-10409711c2ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3., 6., 9.], device='mps:0', dtype=torch.float16)"
      ]
     },
     "execution_count": 502,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float16_tensor = float32_tensor.type(torch.float16)\n",
    "float16_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "id": "2f025f50-3b1d-4dd3-a112-1c1743b83009",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 6., 12., 18.], device='mps:0')"
      ]
     },
     "execution_count": 503,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float32_tensor + cpu_tensor.to(float32_tensor.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee9cacf-fd54-4312-85d4-7af55f0bdcff",
   "metadata": {},
   "source": [
    "# Tensor Manipulation\n",
    "\n",
    "## Tensor Operations\n",
    "\n",
    "* Addition\n",
    "* Subtraction\n",
    "* Element-wise Multiplication\n",
    "* Matrix Multiplication\n",
    "* Division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "id": "85f162bc-19a6-4bff-9e36-08d13ec049f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([11., 12., 13.], device='mps:0')"
      ]
     },
     "execution_count": 504,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = torch.tensor([1., 2., 3.])\n",
    "tensor + 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "id": "30f049a3-3990-43a4-a686-2638248e8c21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10., 20., 30.], device='mps:0')"
      ]
     },
     "execution_count": 505,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor * 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "id": "e209df68-93db-4dcf-b9f4-a2f1a1e898a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10., 20., 30.], device='mps:0')"
      ]
     },
     "execution_count": 506,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor * torch.tensor(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "id": "afade7d9-03de-487d-9c99-6c10a8ae96ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-9., -8., -7.], device='mps:0')"
      ]
     },
     "execution_count": 507,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor - 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "id": "d1a717a5-2749-44b7-b9d0-2fa690a13026",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1000, 0.2000, 0.3000], device='mps:0')"
      ]
     },
     "execution_count": 508,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor / 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "id": "91f5ff2c-ca12-4700-89eb-04bbcf27b5b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 4., 9.], device='mps:0')"
      ]
     },
     "execution_count": 509,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "id": "0614619f-640b-41f0-8dad-acaf50d8805e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10., 20., 30.], device='mps:0')"
      ]
     },
     "execution_count": 510,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mul(tensor, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "id": "78dd6e1c-f1ee-4e84-856b-18bb827e4e75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([11., 12., 13.], device='mps:0')"
      ]
     },
     "execution_count": 511,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.add(tensor, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "id": "7034413b-87a4-4ecc-a1a1-aaa06642a7b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1000, 0.2000, 0.3000], device='mps:0')"
      ]
     },
     "execution_count": 512,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.div(tensor, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "id": "07559e2f-2d57-4c43-a73e-71533343c63f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 4., 9.], device='mps:0')"
      ]
     },
     "execution_count": 513,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.pow(tensor, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "id": "6cd65893-5995-4d34-abe9-9912ada6b0bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-9., -8., -7.], device='mps:0')"
      ]
     },
     "execution_count": 514,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sub(tensor, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "id": "d7a8898b-cca9-4075-baf6-86e13732508c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 4., 9.], device='mps:0')"
      ]
     },
     "execution_count": 515,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Matrix Multiplication\n",
    "\n",
    "## Element-wise\n",
    "\n",
    "tensor * tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "id": "ff95fe91-26f8-43eb-b1c6-d5db8ecf5b68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(14., device='mps:0')"
      ]
     },
     "execution_count": 516,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Dot product\n",
    "torch.matmul(tensor, tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "id": "1d3de132-f9de-44c1-bac7-c9984d58384c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37.2 µs ± 490 ns per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "torch.matmul(tensor, tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "id": "4c9f9e9c-3352-4be5-b5d2-fd774bf0fd40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "301 µs ± 5.35 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "value = 0\n",
    "for element in tensor:\n",
    "    value += element * element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "id": "2ea19f5d-0b45-4b24-89b7-ef4ce207638e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38.7 µs ± 554 ns per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "tensor @ tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "id": "8b7a0da9-0ddc-4a85-bb25-61df894ff5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matmul of N-DIM tensors\n",
    "\n",
    "ndim_tensor = torch.matmul(torch.rand(7, 1, 3, 4), torch.rand(5, 4, 7))\n",
    "# (j x 1 x n x m) @ (k x m x p) -> (j x (k x 1) x [(n x m) @ (m x p)]) = (j x k x n x p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "id": "43d577c4-81a0-4660-b0a6-6e717941923c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7, 5, 3, 7])"
      ]
     },
     "execution_count": 521,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ndim_tensor.shape\n",
    "# j x k x n x p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "id": "012ad0aa-e647-4e75-9e56-ce1edc521070",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1D matrices output :\n",
      " tensor(36., device='mps:0')\n",
      "\n",
      "2D matrices output :\n",
      " tensor([[10., 28., 28.],\n",
      "        [27., 73., 62.],\n",
      "        [13., 37., 53.]], device='mps:0')\n",
      "\n",
      "N-D matrices output :\n",
      " tensor([[[ 0.7953,  0.5231, -0.7751, -0.1757],\n",
      "         [ 3.9030, -0.8274, -5.1287, -0.5915],\n",
      "         [ 2.8487, -0.2372, -3.4850, -1.3212]],\n",
      "\n",
      "        [[ 0.6531, -0.1637, -1.1250,  0.2633],\n",
      "         [-1.5532,  0.4309,  1.6526,  2.5166],\n",
      "         [ 0.6491,  0.8869,  1.4995, -2.3370]]], device='mps:0')\n",
      "\n",
      " Mixed matrices output :\n",
      " tensor([218., 596., 562.], device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "# single dimensional matrices\n",
    "oneD_1 = torch.tensor([3, 6, 2], dtype=torch.float32)\n",
    "oneD_2 = torch.tensor([4, 1, 9], dtype=torch.float32)\n",
    "  \n",
    "  \n",
    "# two dimensional matrices\n",
    "twoD_1 = torch.tensor([[1, 2, 3],\n",
    "                       [4, 3, 8],\n",
    "                       [1, 7, 2]], dtype=torch.float32)\n",
    "twoD_2 = torch.tensor([[2, 4, 1],\n",
    "                       [1, 3, 6],\n",
    "                       [2, 6, 5]], dtype=torch.float32)\n",
    "  \n",
    "# N-dimensional matrices (N>2)\n",
    "  \n",
    "# 2x3x3 dimensional matrix\n",
    "ND_1 = torch.tensor([[[-0.0135, -0.9197, -0.3395],\n",
    "                      [-1.0369, -1.3242,  1.4799],\n",
    "                      [-0.0182, -1.2917,  0.6575]],\n",
    "  \n",
    "                     [[-0.3585, -0.0478,  0.4674],\n",
    "                      [-0.6688, -0.9217, -1.2612],\n",
    "                      [1.6323, -0.0640,  0.4357]]])\n",
    "  \n",
    "# 2x3x4 dimensional matrix\n",
    "ND_2 = torch.tensor([[[0.2431, -0.1044, -0.1437, -1.4982],\n",
    "                      [-1.4318, -0.2510,  1.6247,  0.5623],\n",
    "                      [1.5265, -0.8568, -2.1125, -0.9463]],\n",
    "  \n",
    "                     [[0.0182,  0.5207,  1.2890, -1.3232],\n",
    "                      [-0.2275, -0.8006, -0.6909, -1.0108],\n",
    "                      [1.3881, -0.0327, -1.4890, -0.5550]]])\n",
    "  \n",
    "print(\"1D matrices output :\\n\", oneD_1 @ oneD_2)\n",
    "print(\"\\n2D matrices output :\\n\", twoD_1 @ twoD_2)\n",
    "print(\"\\nN-D matrices output :\\n\", ND_1 @ ND_2) # 2 x 3 x 4\n",
    "print(\"\\n Mixed matrices output :\\n\", oneD_1 @ twoD_1 @ twoD_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddfdf361-b086-44e5-863c-5c82068db27c",
   "metadata": {},
   "source": [
    "## Tensor Aggregation Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "id": "defd3f50-742b-4692-9a45-92e1fe391fd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0., device='mps:0')"
      ]
     },
     "execution_count": 523,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = torch.arange(0., 100., 10)\n",
    "torch.min(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "id": "b6b60da5-f4df-4f71-aa55-923ffa6e4f1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(90., device='mps:0')"
      ]
     },
     "execution_count": 524,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "id": "7834c1dd-6053-4a0e-8d53-2760dfa417c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(450., device='mps:0')"
      ]
     },
     "execution_count": 525,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "id": "5498ae11-ce6e-48a7-9904-4a3e4f0b8e43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(90., device='mps:0')"
      ]
     },
     "execution_count": 526,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "id": "cc15df17-cee7-4ed3-81ed-7281d6c1a397",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0., device='mps:0')"
      ]
     },
     "execution_count": 527,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "id": "81ee593c-7eaf-4871-a0f3-b4314ab2ce82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(450., device='mps:0')"
      ]
     },
     "execution_count": 528,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "id": "6701c2ee-feb9-43f3-a7ab-02a8007f3153",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(45., device='mps:0')"
      ]
     },
     "execution_count": 529,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "id": "2176feff-8b9b-497d-8475-dff196199883",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(40., device='mps:0')"
      ]
     },
     "execution_count": 530,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "id": "2e9eca69-f41e-44a7-955f-dcdeb4607996",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(30.2765, device='mps:0')"
      ]
     },
     "execution_count": 531,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.var().sqrt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "id": "8213ce08-15b9-4600-b3fd-4dda0377321d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(9, device='mps:0')"
      ]
     },
     "execution_count": 532,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "id": "338b6965-8b28-478c-9b68-8b0402f08d1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0, device='mps:0')"
      ]
     },
     "execution_count": 533,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.argmin()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c2bba0-6694-4855-baa9-f935d83fb9f2",
   "metadata": {},
   "source": [
    "## Reshaping and Aggregating Tensors\n",
    "\n",
    "* Reshape -> reshape an input tensor to a given shape\n",
    "* View -> return a view of a given shape from an input tensor (same memory location)\n",
    "* Stack -> combine multiple tensors on top of each other (__vstack__) or side by side (__hstack__)\n",
    "* Squeeze -> remove all `1` dimensions from a tensor\n",
    "* Unsqueeze -> add a `1` dimension to a tensor\n",
    "* Permute -> return a view with permuted (swapped) dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "id": "8a3bf5f2-d443-455f-ae68-055ecebd39eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.], device='mps:0'),\n",
       " torch.Size([10]))"
      ]
     },
     "execution_count": 534,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tensor Reshaping\n",
    "\n",
    "x = torch.arange(1., 11.)\n",
    "x, x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "id": "8dc92df1-042e-42cf-a7bc-685d427fa0ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.],\n",
       "        [ 2.],\n",
       "        [ 3.],\n",
       "        [ 4.],\n",
       "        [ 5.],\n",
       "        [ 6.],\n",
       "        [ 7.],\n",
       "        [ 8.],\n",
       "        [ 9.],\n",
       "        [10.]], device='mps:0')"
      ]
     },
     "execution_count": 535,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_reshaped = x.reshape(10, 1)\n",
    "x_reshaped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "id": "8d5c0704-d61a-4dfc-b63f-7204b8516023",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.,  2.],\n",
       "        [ 3.,  4.],\n",
       "        [ 5.,  6.],\n",
       "        [ 7.,  8.],\n",
       "        [ 9., 10.]], device='mps:0')"
      ]
     },
     "execution_count": 536,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_reshaped = x.reshape(5, 2)\n",
    "x_reshaped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "id": "6b5a1809-2e01-4cac-b5a0-dee7ced54f5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.,  2.],\n",
       "        [ 3.,  4.],\n",
       "        [ 5.,  6.],\n",
       "        [ 7.,  8.],\n",
       "        [ 9., 10.]], device='mps:0')"
      ]
     },
     "execution_count": 537,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = x.view(5, 2)\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "id": "79a37895-6d63-4abb-a529-46642b851cf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 1.,  1.,  1.,  1.],\n",
       "         [ 2.,  2.,  2.,  2.],\n",
       "         [ 3.,  3.,  3.,  3.],\n",
       "         [ 4.,  4.,  4.,  4.],\n",
       "         [ 5.,  5.,  5.,  5.],\n",
       "         [ 6.,  6.,  6.,  6.],\n",
       "         [ 7.,  7.,  7.,  7.],\n",
       "         [ 8.,  8.,  8.,  8.],\n",
       "         [ 9.,  9.,  9.,  9.],\n",
       "         [10., 10., 10., 10.]], device='mps:0'),\n",
       " torch.Size([10, 4]))"
      ]
     },
     "execution_count": 538,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_stacked = torch.stack([x, x, x, x], dim=1)\n",
    "x_stacked, x_stacked.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "id": "a7f9d5ee-43a5-4983-9f07-bca35064e499",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.],\n",
       "         [ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.],\n",
       "         [ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.],\n",
       "         [ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.]], device='mps:0'),\n",
       " torch.Size([4, 10]))"
      ]
     },
     "execution_count": 539,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_stacked = torch.stack([x, x, x, x], dim=0)\n",
    "x_stacked, x_stacked.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "id": "8e9afe86-5f20-4a67-96f9-1ca2b1d3d064",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 1.],\n",
       "         [ 2.],\n",
       "         [ 3.],\n",
       "         [ 4.],\n",
       "         [ 5.],\n",
       "         [ 6.],\n",
       "         [ 7.],\n",
       "         [ 8.],\n",
       "         [ 9.],\n",
       "         [10.]], device='mps:0'),\n",
       " tensor([ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.], device='mps:0'),\n",
       " torch.Size([10]))"
      ]
     },
     "execution_count": 540,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_unsqueezed = torch.arange(1., 11.).reshape(10, 1)\n",
    "x_squeezed = torch.squeeze(x_unsqueezed)\n",
    "x_unsqueezed, x_squeezed, x_squeezed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "id": "c692c564-5664-4e69-a578-981db4fbbe39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.], device='mps:0'),\n",
       " tensor([[ 1.],\n",
       "         [ 2.],\n",
       "         [ 3.],\n",
       "         [ 4.],\n",
       "         [ 5.],\n",
       "         [ 6.],\n",
       "         [ 7.],\n",
       "         [ 8.],\n",
       "         [ 9.],\n",
       "         [10.]], device='mps:0'),\n",
       " torch.Size([10, 1]))"
      ]
     },
     "execution_count": 541,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_unsqueezed = torch.unsqueeze(x_squeezed, dim=-1)\n",
    "x_squeezed, x_unsqueezed, x_unsqueezed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "id": "438e2546-0b85-4cc8-8c1c-d7141902c6bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 1.],\n",
       "         [ 2.],\n",
       "         [ 3.],\n",
       "         [ 4.],\n",
       "         [ 5.],\n",
       "         [ 6.],\n",
       "         [ 7.],\n",
       "         [ 8.],\n",
       "         [ 9.],\n",
       "         [10.]], device='mps:0'),\n",
       " tensor([[ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.]], device='mps:0'),\n",
       " torch.Size([1, 10]))"
      ]
     },
     "execution_count": 542,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_permuted = torch.permute(x_unsqueezed, dims=(1, 0))\n",
    "x_unsqueezed, x_permuted, x_permuted.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "id": "80e453d6-3dbf-406f-9c7e-93877e3b75db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([224, 224, 3]), torch.Size([3, 224, 224]))"
      ]
     },
     "execution_count": 543,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# permute is useful for Computer Vision\n",
    "image = torch.rand(224, 224, 3)\n",
    "\n",
    "image_permuted = image.permute(2, 0, 1)\n",
    "\n",
    "image.shape, image_permuted.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5901b55d-8acc-444e-a8b0-610c878004d6",
   "metadata": {},
   "source": [
    "## Tensor Access Patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "id": "6c1f7206-459d-4c68-bb46-8172ac746f3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[1, 2, 3],\n",
       "          [4, 5, 6],\n",
       "          [7, 8, 9]]], device='mps:0'),\n",
       " torch.Size([1, 3, 3]))"
      ]
     },
     "execution_count": 544,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Indexing\n",
    "\n",
    "x = torch.arange(1, 10).reshape(1, 3, 3)\n",
    "x, x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "id": "52dacc0e-1022-442a-9faf-e77ebfff8487",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1, 2, 3],\n",
       "         [4, 5, 6],\n",
       "         [7, 8, 9]], device='mps:0'),\n",
       " torch.Size([3, 3]))"
      ]
     },
     "execution_count": 545,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0], x[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "id": "6d2a96f0-a560-42d2-a822-9dbc93f4dcf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1, 2, 3]], device='mps:0'), torch.Size([1, 3]))"
      ]
     },
     "execution_count": 546,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:, 0], x[:, 0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "id": "2c31a2bc-d3c2-4480-b298-c2f8b6c63a5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1, 2, 3], device='mps:0'), torch.Size([3]))"
      ]
     },
     "execution_count": 547,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0, 0], x[0, 0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "id": "964bf00e-4c88-4985-b761-6ad7a0cc1d90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1, device='mps:0')"
      ]
     },
     "execution_count": 548,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "id": "34973074-9c4a-4a8c-8113-94d28a8e45a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2, device='mps:0')"
      ]
     },
     "execution_count": 549,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0, 0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "id": "3fb67fc9-9ec0-4388-a352-58dffbd0b376",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4, device='mps:0')"
      ]
     },
     "execution_count": 550,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0, 1, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "id": "6aa73875-58d3-45b7-b23f-33b765b2b678",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3]], device='mps:0')"
      ]
     },
     "execution_count": 551,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:, 0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "id": "b3308fce-6b26-4d46-bd6e-614652eee47c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 4, 7]], device='mps:0')"
      ]
     },
     "execution_count": 552,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:, :, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35196701-a33c-4502-b1fc-92b18897eb51",
   "metadata": {},
   "source": [
    "## Interacting with NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "id": "8d1f22d2-6fa1-423d-95c6-6244f49f8898",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1., 2., 3., 4., 5., 6., 7.]),\n",
       " (7,),\n",
       " tensor([1., 2., 3., 4., 5., 6., 7.], dtype=torch.float64),\n",
       " torch.Size([7]))"
      ]
     },
     "execution_count": 553,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# From NumPy\n",
    "\n",
    "array = np.arange(1., 8.)\n",
    "tensor = torch.from_numpy(array)\n",
    "\n",
    "# .from_numpy will convert to float64!\n",
    "# array and tensor SHARE MEMORY!\n",
    "\n",
    "array, array.shape, tensor, tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "id": "2b8a7539-82b0-4b16-b942-96f7c1f7da9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([11., 12., 13., 14., 15., 16., 17.]),\n",
       " tensor([11., 12., 13., 14., 15., 16., 17.], dtype=torch.float64))"
      ]
     },
     "execution_count": 554,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array += 10\n",
    "\n",
    "array, tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "id": "0440e1ef-f481-4ee5-986b-57334aff3379",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1., 2., 3., 4., 5., 6., 7.]),\n",
       " tensor([1., 2., 3., 4., 5., 6., 7.], dtype=torch.float64))"
      ]
     },
     "execution_count": 555,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor -= 10\n",
    "\n",
    "array, tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "id": "f5e247b6-9220-4542-ac13-eaf500f12aa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 1., 1., 1., 1., 1., 1.], device='mps:0'),\n",
       " torch.Size([7]),\n",
       " array([1., 1., 1., 1., 1., 1., 1.], dtype=float32),\n",
       " (7,))"
      ]
     },
     "execution_count": 556,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To NumPy\n",
    "\n",
    "tensor = torch.ones(7)\n",
    "numpy_tensor = tensor.cpu().numpy()\n",
    "\n",
    "# If the tensor is on GPU, call .cpu() before .numpy()\n",
    "# .numpy will convert to float32!\n",
    "\n",
    "tensor, tensor.shape, numpy_tensor, numpy_tensor.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb34574-07c2-43de-9d26-7b8a945a1ecd",
   "metadata": {},
   "source": [
    "# Reproducibility in PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "id": "7a4ba36e-1dd3-4902-825c-c45f9885afee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[8.1718e-01, 5.8811e-01, 5.5805e-01, 7.6914e-01],\n",
       "         [3.3936e-01, 4.5596e-01, 6.7508e-01, 4.4060e-04],\n",
       "         [4.0876e-01, 1.7912e-01, 5.9732e-01, 8.4722e-01]], device='mps:0'),\n",
       " tensor([[0.0661, 0.3270, 0.5155, 0.2259],\n",
       "         [0.8333, 0.5891, 0.2452, 0.5659],\n",
       "         [0.4646, 0.4861, 0.5399, 0.6836]], device='mps:0'),\n",
       " tensor([[False, False, False, False],\n",
       "         [False, False, False, False],\n",
       "         [False, False, False, False]], device='mps:0'))"
      ]
     },
     "execution_count": 557,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RANDOM_SEED = 42\n",
    "\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "\n",
    "random_tensor_A = torch.rand(3, 4)\n",
    "random_tensor_B = torch.rand(3, 4)\n",
    "\n",
    "random_tensor_A, random_tensor_B, random_tensor_A == random_tensor_B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "id": "b62a32be-8285-4ca3-a34b-324dc95f6c75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[True, True, True, True],\n",
       "         [True, True, True, True],\n",
       "         [True, True, True, True]], device='mps:0'),\n",
       " tensor([[True, True, True, True],\n",
       "         [True, True, True, True],\n",
       "         [True, True, True, True]], device='mps:0'))"
      ]
     },
     "execution_count": 558,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(RANDOM_SEED)\n",
    "\n",
    "random_tensor_A = torch.rand(3, 4)\n",
    "random_tensor_C = torch.rand(3, 4)\n",
    "\n",
    "\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "\n",
    "random_tensor_B = torch.rand(3, 4)\n",
    "random_tensor_D = torch.rand(3, 4)\n",
    "\n",
    "\n",
    "random_tensor_A == random_tensor_B, random_tensor_C == random_tensor_D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e12b932-6ea5-463d-9088-dd2d799e3d8c",
   "metadata": {},
   "source": [
    "# PyTorch on GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "id": "0c84b36e-fe83-43c1-bffa-2c5fcc6c5b43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(False, False)"
      ]
     },
     "execution_count": 559,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for GPU access\n",
    "\n",
    "torch.cuda.is_available(), torch.backends.cuda.is_built()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "id": "1b9c893b-209e-4302-8074-2d02f0e260a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, True)"
      ]
     },
     "execution_count": 560,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.backends.mps.is_available(), torch.backends.mps.is_built()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "id": "bde50ceb-b36a-461f-a546-eb79f50fd010",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 561,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.backends.cudnn.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "id": "1dc1f656-6b93-4949-98bd-eb1ac322b865",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mps'"
      ]
     },
     "execution_count": 562,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Device Agnostic Code\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "id": "58d06d7a-814c-4e89-9cb9-3e0dbdb872a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 563,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count number of CUDA GPUs\n",
    "\n",
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "id": "69d6a45c-1fe1-4320-accd-85fc0d5c82dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1, 2, 3]), device(type='cpu'))"
      ]
     },
     "execution_count": 564,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Putting tensors and models on the GPU\n",
    "\n",
    "tensor = torch.tensor([1, 2, 3], device=\"cpu\")\n",
    "\n",
    "tensor, tensor.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "id": "6cf47169-1010-4ae0-8e6c-6580a45de55a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1, 2, 3], device='mps:0'), device(type='mps', index=0))"
      ]
     },
     "execution_count": 565,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Move to GPU if available\n",
    "\n",
    "tensor_on_gpu = tensor.to(DEVICE)\n",
    "\n",
    "tensor_on_gpu, tensor_on_gpu.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "id": "d508681c-38af-4028-a6d3-cc8a2ae775fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3])"
      ]
     },
     "execution_count": 566,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Back to CPU\n",
    "\n",
    "tensor_on_gpu.cpu().numpy()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
