{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 569,
   "id": "16fbf5ee-39c8-467e-a8d4-1a7b9a8f7518",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "id": "e12caef2-dac9-46a4-a352-3fd96b8cf9a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.], device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "if torch.backends.mps.is_available():\n",
    "    mps_device = torch.set_default_device(\"mps\")\n",
    "    x = torch.ones(1, device=mps_device)\n",
    "    print (x)\n",
    "else:\n",
    "    print (\"MPS device not found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "747e6267-0758-4b8a-802c-b4aa3957a998",
   "metadata": {},
   "source": [
    "# Creating Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "id": "aa5d4c88-8125-4400-8b10-abe9227dea81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7, device='mps:0')"
      ]
     },
     "execution_count": 571,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scalar\n",
    "\n",
    "scalar = torch.tensor(7)\n",
    "scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "id": "2c9d1524-723a-40d7-8406-14dbc75142c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 572,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "id": "172084bd-62fa-4a55-858b-a9f6e95c4e79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 573,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar.item() # Get POPO back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "id": "5b571bc8-f0ad-4922-8332-86548d82d8f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7, 7], device='mps:0')"
      ]
     },
     "execution_count": 574,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vector\n",
    "\n",
    "vector = torch.tensor([7, 7])\n",
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "id": "2dcef92e-82e3-4a11-bcf2-602f4f8b4f86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 575,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector.ndim # Dimension of the tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "id": "dbcd8c50-cc9f-4cc2-9ba5-3491e88fdc9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2])"
      ]
     },
     "execution_count": 576,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector.shape # Shape of the tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "id": "3c3a556b-1e33-4b80-a40a-f4a6572a471d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 7,  8],\n",
       "        [ 9, 10]], device='mps:0')"
      ]
     },
     "execution_count": 577,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MATRIX\n",
    "\n",
    "matrix = torch.tensor(\n",
    "    [[7, 8],\n",
    "     [9, 10]]\n",
    ")\n",
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "id": "9d715800-e8c7-48da-8ccc-4e12d3b03f13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 578,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "id": "e8a966d4-ef7c-4e19-8e28-31ab5bb8b11e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7, 8], device='mps:0')"
      ]
     },
     "execution_count": 579,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "id": "c34b0b09-df1d-489a-9c56-ea669d4ff71e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2])"
      ]
     },
     "execution_count": 580,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "id": "ae507133-a07a-4436-8d1c-0c2edd57553b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 2, 3],\n",
       "         [4, 5, 6],\n",
       "         [7, 8, 9]]], device='mps:0')"
      ]
     },
     "execution_count": 581,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TENSOR\n",
    "\n",
    "tensor = torch.tensor(\n",
    "    [[[1, 2, 3],\n",
    "      [4, 5, 6],\n",
    "      [7, 8, 9]]]\n",
    ")\n",
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "id": "ff01e33f-4fbf-441c-bf96-5d5fd0cd0a97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [4, 5, 6],\n",
       "        [7, 8, 9]], device='mps:0')"
      ]
     },
     "execution_count": 582,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "id": "ffb377b8-7efb-46fa-85fd-996d6730854d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3], device='mps:0')"
      ]
     },
     "execution_count": 583,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor[0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "id": "9c3e5485-66f3-405d-bc9f-b8231e4eba71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7, 8, 9], device='mps:0')"
      ]
     },
     "execution_count": 584,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor[0, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "id": "dbdc636e-2152-4aee-a478-f3d6e1fe3163",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 585,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "id": "687b6829-0fd3-4c99-9e2c-d6beae19c3cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 3])"
      ]
     },
     "execution_count": 586,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d20c27e-d682-4e0f-8c08-d7300a4a9c7e",
   "metadata": {},
   "source": [
    "## Random Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "id": "85f4b018-2e5b-4e5e-8f64-7e287f105161",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5880, 0.2433, 0.5797, 0.6805],\n",
       "        [0.5575, 0.3254, 0.4291, 0.2087],\n",
       "        [0.0562, 0.2676, 0.1369, 0.5249]], device='mps:0')"
      ]
     },
     "execution_count": 587,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random Tensor\n",
    "random_tensor = torch.rand(3, 4)\n",
    "random_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "id": "11798346-a124-4ad2-8921-fe48013b4ba9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 588,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_tensor.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "id": "4ea4723d-7d01-4b2b-9844-30948343d845",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 4])"
      ]
     },
     "execution_count": 589,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "id": "40dcb926-5e36-4368-8ca1-2e5fe2d70397",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6543, 0.4484, 0.3422]], device='mps:0')"
      ]
     },
     "execution_count": 590,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_tensor = torch.rand(1, 3)\n",
    "random_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "id": "f400f6ba-952a-48f6-9a15-af2ee3d7ef7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9979],\n",
       "        [0.5881],\n",
       "        [0.8746]], device='mps:0')"
      ]
     },
     "execution_count": 591,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_tensor = torch.rand(3, 1)\n",
    "random_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "id": "dbc47ca3-0ea1-46fb-b98d-d6ebf8a1c8ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0266, 0.3488, 0.8557], device='mps:0')"
      ]
     },
     "execution_count": 592,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_tensor = torch.rand(3)\n",
    "random_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "id": "c6582c65-96d6-4053-94d9-cb69b1107a51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7142608165740967"
      ]
     },
     "execution_count": 593,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_tensor = torch.rand(1)\n",
    "random_tensor.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "id": "6aa37e16-541f-42ec-822c-305381c46e7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[6.5081e-01, 1.3483e-02, 4.0091e-01],\n",
       "         [7.5908e-01, 6.2280e-01, 3.0647e-01],\n",
       "         [7.0718e-01, 2.8794e-01, 9.5678e-01],\n",
       "         ...,\n",
       "         [2.7218e-01, 4.1125e-01, 5.4225e-01],\n",
       "         [5.5374e-01, 1.4264e-01, 3.1442e-01],\n",
       "         [3.9933e-01, 8.2867e-01, 1.6032e-01]],\n",
       "\n",
       "        [[3.6701e-01, 2.3252e-01, 5.6303e-01],\n",
       "         [8.9301e-01, 3.8343e-01, 2.6777e-01],\n",
       "         [2.7210e-01, 4.5447e-01, 2.7387e-01],\n",
       "         ...,\n",
       "         [2.6051e-01, 2.8597e-01, 5.1109e-01],\n",
       "         [7.9585e-01, 5.9987e-01, 1.5737e-01],\n",
       "         [1.4087e-01, 4.8229e-01, 2.2150e-01]],\n",
       "\n",
       "        [[2.2679e-02, 9.2896e-01, 2.7301e-01],\n",
       "         [2.2105e-01, 5.4439e-01, 7.5555e-04],\n",
       "         [2.7342e-01, 5.9997e-01, 1.6717e-01],\n",
       "         ...,\n",
       "         [9.5588e-01, 5.4159e-01, 9.7300e-01],\n",
       "         [1.8556e-01, 1.4898e-01, 2.8003e-01],\n",
       "         [9.7155e-01, 5.4521e-01, 1.6405e-02]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[7.8175e-01, 3.5803e-02, 5.7587e-01],\n",
       "         [8.6118e-01, 1.6885e-01, 3.4999e-01],\n",
       "         [1.8054e-01, 1.3534e-01, 9.6811e-01],\n",
       "         ...,\n",
       "         [1.4198e-01, 3.2563e-01, 6.0857e-01],\n",
       "         [9.7838e-01, 6.8307e-05, 1.2881e-01],\n",
       "         [4.0647e-01, 8.5643e-01, 8.5943e-01]],\n",
       "\n",
       "        [[4.0381e-01, 4.0155e-01, 7.4980e-01],\n",
       "         [9.6661e-01, 6.4848e-01, 8.6075e-02],\n",
       "         [7.4819e-01, 8.6671e-01, 5.0686e-01],\n",
       "         ...,\n",
       "         [2.0890e-01, 6.6239e-01, 1.7680e-02],\n",
       "         [8.3426e-01, 6.2515e-01, 9.3761e-01],\n",
       "         [1.5543e-01, 1.9907e-01, 2.2512e-01]],\n",
       "\n",
       "        [[3.2440e-01, 3.1372e-01, 1.0626e-01],\n",
       "         [9.0688e-01, 7.9069e-01, 4.0888e-01],\n",
       "         [6.0779e-01, 7.5546e-01, 5.4918e-01],\n",
       "         ...,\n",
       "         [6.4006e-01, 1.3333e-01, 4.2006e-01],\n",
       "         [4.0317e-01, 9.3146e-02, 9.7575e-01],\n",
       "         [2.6343e-01, 6.2594e-01, 1.6123e-01]]], device='mps:0')"
      ]
     },
     "execution_count": 594,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random Tensor with same shape as image tensor\n",
    "# height, width, colour channels (R, G, B) \n",
    "random_image_size_tensor = torch.rand(size=(224, 224, 3))\n",
    "random_image_size_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "id": "b06815e6-35eb-42a3-b491-589c9b510b1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8163, 0.9157, 0.7564, 0.8756],\n",
      "        [0.8721, 0.6721, 0.9948, 0.0559],\n",
      "        [0.8953, 0.6170, 0.9749, 0.3199]], device='mps:0')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 595,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random Tensor of 0 and 1\n",
    "random_tensor = torch.rand(3, 4)\n",
    "zeros = torch.zeros(random_tensor[0].shape)\n",
    "print(random_tensor)\n",
    "zeros.dot(random_tensor).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 596,
   "id": "cfc44d03-d426-4d14-98b2-3e3e608e7f4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5419, 0.4420, 0.3914, 0.5802],\n",
      "        [0.4462, 0.8912, 0.1805, 0.3882],\n",
      "        [0.4244, 0.9132, 0.6135, 0.7112]], device='mps:0')\n",
      "tensor(6.5239, device='mps:0')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(6.5239, device='mps:0')"
      ]
     },
     "execution_count": 596,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random Tensor of 0 and 1\n",
    "random_tensor = torch.rand(3, 4)\n",
    "ones = torch.ones(random_tensor[0].shape)\n",
    "print(random_tensor)\n",
    "print(ones.dot(random_tensor)) # sum of all elements\n",
    "random_tensor.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 597,
   "id": "4e7f53d7-da83-444f-8331-10cff991dc31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 597,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ones.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 598,
   "id": "4fc36c62-e8d4-4c79-96dc-8ea643136550",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 598,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zeros.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c528814-ce9b-4af7-9d11-89f3debd23dc",
   "metadata": {},
   "source": [
    "## Creating tensors from fixed ranges and other tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 599,
   "id": "3b44b15d-900b-43c2-916a-cf05a6144cc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], device='mps:0')"
      ]
     },
     "execution_count": 599,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(0, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 600,
   "id": "469cf469-cce4-443e-8a90-6f9d0f4618a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  0,  77, 154, 231, 308, 385, 462, 539, 616, 693, 770, 847, 924],\n",
       "       device='mps:0')"
      ]
     },
     "execution_count": 600,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(start=0, end=1000, step=77)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 601,
   "id": "66eb222d-97f4-4cd9-9236-c63c2e968f37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='mps:0')"
      ]
     },
     "execution_count": 601,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Copy tensor\n",
    "one_to_ten = torch.arange(start=1, end=11, step=1)\n",
    "ten_zeros = torch.zeros_like(one_to_ten)\n",
    "ten_zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "id": "014fdb99-d5fe-4a80-99bd-7945d7e88518",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3., 6., 9.], device='mps:0')"
      ]
     },
     "execution_count": 602,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float32_tensor = torch.tensor([3.0, 6.0, 9.0], dtype=None)\n",
    "float32_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 603,
   "id": "2d387b63-5fe8-45b2-9524-fec7f973aba7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 603,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float32_tensor.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "id": "83e337e4-00d4-4223-ae12-155794e5ba54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3., 6., 9.], device='mps:0', dtype=torch.float16)"
      ]
     },
     "execution_count": 604,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float16_tensor = torch.tensor([3.0, 6.0, 9.0], dtype=torch.float16)\n",
    "float16_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "id": "dd512cb4-7059-4fcb-a7aa-406c0ba99dfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float16"
      ]
     },
     "execution_count": 605,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float16_tensor.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 606,
   "id": "3144e088-a936-4543-af0a-7adec518736d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int64"
      ]
     },
     "execution_count": 606,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int64_tensor = torch.tensor([3, 6, 9], dtype=None)\n",
    "int64_tensor.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 607,
   "id": "f49110ad-3f48-42da-95fe-c57ce9767d0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3., 6., 9.])"
      ]
     },
     "execution_count": 607,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cpu_tensor = torch.tensor([3.0, 6.0, 9.0], device=\"cpu\")\n",
    "cpu_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 608,
   "id": "c3a824b6-10bc-4487-9c45-89bce125a2bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3., 6., 9.], device='mps:0')"
      ]
     },
     "execution_count": 608,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nograd_tensor = torch.tensor([3.0, 6.0, 9.0], requires_grad=False)\n",
    "nograd_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c6f0ff-4a9d-4a80-bc83-9879df254590",
   "metadata": {},
   "source": [
    "# Tensor Datatypes\n",
    "\n",
    "3 common pitfalls:\n",
    "\n",
    "1. Tensors not right datatype\n",
    "2. Tensors not right shape\n",
    "3. Tensors not on the right device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 609,
   "id": "abbe99f7-5ee3-48c1-8b95-10409711c2ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3., 6., 9.], device='mps:0', dtype=torch.float16)"
      ]
     },
     "execution_count": 609,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float16_tensor = float32_tensor.type(torch.float16)\n",
    "float16_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 610,
   "id": "2f025f50-3b1d-4dd3-a112-1c1743b83009",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 6., 12., 18.], device='mps:0')"
      ]
     },
     "execution_count": 610,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float32_tensor + cpu_tensor.to(float32_tensor.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee9cacf-fd54-4312-85d4-7af55f0bdcff",
   "metadata": {},
   "source": [
    "# Tensor Manipulation\n",
    "\n",
    "## Tensor Operations\n",
    "\n",
    "* Addition\n",
    "* Subtraction\n",
    "* Element-wise Multiplication\n",
    "* Matrix Multiplication\n",
    "* Division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "id": "85f162bc-19a6-4bff-9e36-08d13ec049f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([11., 12., 13.], device='mps:0')"
      ]
     },
     "execution_count": 611,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = torch.tensor([1., 2., 3.])\n",
    "tensor + 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 612,
   "id": "30f049a3-3990-43a4-a686-2638248e8c21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10., 20., 30.], device='mps:0')"
      ]
     },
     "execution_count": 612,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor * 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "id": "e209df68-93db-4dcf-b9f4-a2f1a1e898a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10., 20., 30.], device='mps:0')"
      ]
     },
     "execution_count": 613,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor * torch.tensor(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 614,
   "id": "afade7d9-03de-487d-9c99-6c10a8ae96ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-9., -8., -7.], device='mps:0')"
      ]
     },
     "execution_count": 614,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor - 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 615,
   "id": "d1a717a5-2749-44b7-b9d0-2fa690a13026",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1000, 0.2000, 0.3000], device='mps:0')"
      ]
     },
     "execution_count": 615,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor / 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 616,
   "id": "91f5ff2c-ca12-4700-89eb-04bbcf27b5b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 4., 9.], device='mps:0')"
      ]
     },
     "execution_count": 616,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "id": "0614619f-640b-41f0-8dad-acaf50d8805e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10., 20., 30.], device='mps:0')"
      ]
     },
     "execution_count": 617,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mul(tensor, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "id": "78dd6e1c-f1ee-4e84-856b-18bb827e4e75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([11., 12., 13.], device='mps:0')"
      ]
     },
     "execution_count": 618,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.add(tensor, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "id": "7034413b-87a4-4ecc-a1a1-aaa06642a7b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1000, 0.2000, 0.3000], device='mps:0')"
      ]
     },
     "execution_count": 619,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.div(tensor, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "id": "07559e2f-2d57-4c43-a73e-71533343c63f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 4., 9.], device='mps:0')"
      ]
     },
     "execution_count": 620,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.pow(tensor, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "id": "6cd65893-5995-4d34-abe9-9912ada6b0bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-9., -8., -7.], device='mps:0')"
      ]
     },
     "execution_count": 621,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sub(tensor, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "id": "d7a8898b-cca9-4075-baf6-86e13732508c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 4., 9.], device='mps:0')"
      ]
     },
     "execution_count": 622,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Matrix Multiplication\n",
    "\n",
    "## Element-wise\n",
    "\n",
    "tensor * tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 623,
   "id": "ff95fe91-26f8-43eb-b1c6-d5db8ecf5b68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(14., device='mps:0')"
      ]
     },
     "execution_count": 623,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Dot product\n",
    "torch.matmul(tensor, tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 624,
   "id": "1d3de132-f9de-44c1-bac7-c9984d58384c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36.9 µs ± 669 ns per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "torch.matmul(tensor, tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 625,
   "id": "4c9f9e9c-3352-4be5-b5d2-fd774bf0fd40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "281 µs ± 1.29 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "value = 0\n",
    "for element in tensor:\n",
    "    value += element * element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 626,
   "id": "2ea19f5d-0b45-4b24-89b7-ef4ce207638e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37 µs ± 338 ns per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "tensor @ tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 627,
   "id": "8b7a0da9-0ddc-4a85-bb25-61df894ff5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matmul of N-DIM tensors\n",
    "\n",
    "ndim_tensor = torch.matmul(torch.rand(7, 1, 3, 4), torch.rand(5, 4, 7))\n",
    "# (j x 1 x n x m) @ (k x m x p) -> (j x (k x 1) x [(n x m) @ (m x p)]) = (j x k x n x p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 628,
   "id": "43d577c4-81a0-4660-b0a6-6e717941923c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7, 5, 3, 7])"
      ]
     },
     "execution_count": 628,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ndim_tensor.shape\n",
    "# j x k x n x p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 629,
   "id": "012ad0aa-e647-4e75-9e56-ce1edc521070",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1D matrices output :\n",
      " tensor(36., device='mps:0')\n",
      "\n",
      "2D matrices output :\n",
      " tensor([[10., 28., 28.],\n",
      "        [27., 73., 62.],\n",
      "        [13., 37., 53.]], device='mps:0')\n",
      "\n",
      "N-D matrices output :\n",
      " tensor([[[ 0.7953,  0.5231, -0.7751, -0.1757],\n",
      "         [ 3.9030, -0.8274, -5.1287, -0.5915],\n",
      "         [ 2.8487, -0.2372, -3.4850, -1.3212]],\n",
      "\n",
      "        [[ 0.6531, -0.1637, -1.1250,  0.2633],\n",
      "         [-1.5532,  0.4309,  1.6526,  2.5166],\n",
      "         [ 0.6491,  0.8869,  1.4995, -2.3370]]], device='mps:0')\n",
      "\n",
      " Mixed matrices output :\n",
      " tensor([218., 596., 562.], device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "# single dimensional matrices\n",
    "oneD_1 = torch.tensor([3, 6, 2], dtype=torch.float32)\n",
    "oneD_2 = torch.tensor([4, 1, 9], dtype=torch.float32)\n",
    "  \n",
    "  \n",
    "# two dimensional matrices\n",
    "twoD_1 = torch.tensor([[1, 2, 3],\n",
    "                       [4, 3, 8],\n",
    "                       [1, 7, 2]], dtype=torch.float32)\n",
    "twoD_2 = torch.tensor([[2, 4, 1],\n",
    "                       [1, 3, 6],\n",
    "                       [2, 6, 5]], dtype=torch.float32)\n",
    "  \n",
    "# N-dimensional matrices (N>2)\n",
    "  \n",
    "# 2x3x3 dimensional matrix\n",
    "ND_1 = torch.tensor([[[-0.0135, -0.9197, -0.3395],\n",
    "                      [-1.0369, -1.3242,  1.4799],\n",
    "                      [-0.0182, -1.2917,  0.6575]],\n",
    "  \n",
    "                     [[-0.3585, -0.0478,  0.4674],\n",
    "                      [-0.6688, -0.9217, -1.2612],\n",
    "                      [1.6323, -0.0640,  0.4357]]])\n",
    "  \n",
    "# 2x3x4 dimensional matrix\n",
    "ND_2 = torch.tensor([[[0.2431, -0.1044, -0.1437, -1.4982],\n",
    "                      [-1.4318, -0.2510,  1.6247,  0.5623],\n",
    "                      [1.5265, -0.8568, -2.1125, -0.9463]],\n",
    "  \n",
    "                     [[0.0182,  0.5207,  1.2890, -1.3232],\n",
    "                      [-0.2275, -0.8006, -0.6909, -1.0108],\n",
    "                      [1.3881, -0.0327, -1.4890, -0.5550]]])\n",
    "  \n",
    "print(\"1D matrices output :\\n\", oneD_1 @ oneD_2)\n",
    "print(\"\\n2D matrices output :\\n\", twoD_1 @ twoD_2)\n",
    "print(\"\\nN-D matrices output :\\n\", ND_1 @ ND_2) # 2 x 3 x 4\n",
    "print(\"\\n Mixed matrices output :\\n\", oneD_1 @ twoD_1 @ twoD_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddfdf361-b086-44e5-863c-5c82068db27c",
   "metadata": {},
   "source": [
    "## Tensor Aggregation Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 630,
   "id": "defd3f50-742b-4692-9a45-92e1fe391fd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0., device='mps:0')"
      ]
     },
     "execution_count": 630,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = torch.arange(0., 100., 10)\n",
    "torch.min(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 631,
   "id": "b6b60da5-f4df-4f71-aa55-923ffa6e4f1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(90., device='mps:0')"
      ]
     },
     "execution_count": 631,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 632,
   "id": "7834c1dd-6053-4a0e-8d53-2760dfa417c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(450., device='mps:0')"
      ]
     },
     "execution_count": 632,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 633,
   "id": "5498ae11-ce6e-48a7-9904-4a3e4f0b8e43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(90., device='mps:0')"
      ]
     },
     "execution_count": 633,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 634,
   "id": "cc15df17-cee7-4ed3-81ed-7281d6c1a397",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0., device='mps:0')"
      ]
     },
     "execution_count": 634,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 635,
   "id": "81ee593c-7eaf-4871-a0f3-b4314ab2ce82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(450., device='mps:0')"
      ]
     },
     "execution_count": 635,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 636,
   "id": "6701c2ee-feb9-43f3-a7ab-02a8007f3153",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(45., device='mps:0')"
      ]
     },
     "execution_count": 636,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 637,
   "id": "2176feff-8b9b-497d-8475-dff196199883",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(40., device='mps:0')"
      ]
     },
     "execution_count": 637,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 638,
   "id": "2e9eca69-f41e-44a7-955f-dcdeb4607996",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(30.2765, device='mps:0')"
      ]
     },
     "execution_count": 638,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.var().sqrt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 639,
   "id": "8213ce08-15b9-4600-b3fd-4dda0377321d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(9, device='mps:0')"
      ]
     },
     "execution_count": 639,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 640,
   "id": "338b6965-8b28-478c-9b68-8b0402f08d1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0, device='mps:0')"
      ]
     },
     "execution_count": 640,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.argmin()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c2bba0-6694-4855-baa9-f935d83fb9f2",
   "metadata": {},
   "source": [
    "## Reshaping and Aggregating Tensors\n",
    "\n",
    "* Reshape -> reshape an input tensor to a given shape\n",
    "* View -> return a view of a given shape from an input tensor (same memory location)\n",
    "* Stack -> combine multiple tensors on top of each other (__vstack__) or side by side (__hstack__)\n",
    "* Squeeze -> remove all `1` dimensions from a tensor\n",
    "* Unsqueeze -> add a `1` dimension to a tensor\n",
    "* Permute -> return a view with permuted (swapped) dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 641,
   "id": "8a3bf5f2-d443-455f-ae68-055ecebd39eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.], device='mps:0'),\n",
       " torch.Size([10]))"
      ]
     },
     "execution_count": 641,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tensor Reshaping\n",
    "\n",
    "x = torch.arange(1., 11.)\n",
    "x, x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 642,
   "id": "8dc92df1-042e-42cf-a7bc-685d427fa0ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.],\n",
       "        [ 2.],\n",
       "        [ 3.],\n",
       "        [ 4.],\n",
       "        [ 5.],\n",
       "        [ 6.],\n",
       "        [ 7.],\n",
       "        [ 8.],\n",
       "        [ 9.],\n",
       "        [10.]], device='mps:0')"
      ]
     },
     "execution_count": 642,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_reshaped = x.reshape(10, 1)\n",
    "x_reshaped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 643,
   "id": "8d5c0704-d61a-4dfc-b63f-7204b8516023",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.,  2.],\n",
       "        [ 3.,  4.],\n",
       "        [ 5.,  6.],\n",
       "        [ 7.,  8.],\n",
       "        [ 9., 10.]], device='mps:0')"
      ]
     },
     "execution_count": 643,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_reshaped = x.reshape(5, 2)\n",
    "x_reshaped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 644,
   "id": "6b5a1809-2e01-4cac-b5a0-dee7ced54f5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.,  2.],\n",
       "        [ 3.,  4.],\n",
       "        [ 5.,  6.],\n",
       "        [ 7.,  8.],\n",
       "        [ 9., 10.]], device='mps:0')"
      ]
     },
     "execution_count": 644,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = x.view(5, 2)\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 645,
   "id": "79a37895-6d63-4abb-a529-46642b851cf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 1.,  1.,  1.,  1.],\n",
       "         [ 2.,  2.,  2.,  2.],\n",
       "         [ 3.,  3.,  3.,  3.],\n",
       "         [ 4.,  4.,  4.,  4.],\n",
       "         [ 5.,  5.,  5.,  5.],\n",
       "         [ 6.,  6.,  6.,  6.],\n",
       "         [ 7.,  7.,  7.,  7.],\n",
       "         [ 8.,  8.,  8.,  8.],\n",
       "         [ 9.,  9.,  9.,  9.],\n",
       "         [10., 10., 10., 10.]], device='mps:0'),\n",
       " torch.Size([10, 4]))"
      ]
     },
     "execution_count": 645,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_stacked = torch.stack([x, x, x, x], dim=1)\n",
    "x_stacked, x_stacked.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 646,
   "id": "a7f9d5ee-43a5-4983-9f07-bca35064e499",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.],\n",
       "         [ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.],\n",
       "         [ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.],\n",
       "         [ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.]], device='mps:0'),\n",
       " torch.Size([4, 10]))"
      ]
     },
     "execution_count": 646,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_stacked = torch.stack([x, x, x, x], dim=0)\n",
    "x_stacked, x_stacked.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 647,
   "id": "8e9afe86-5f20-4a67-96f9-1ca2b1d3d064",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 1.],\n",
       "         [ 2.],\n",
       "         [ 3.],\n",
       "         [ 4.],\n",
       "         [ 5.],\n",
       "         [ 6.],\n",
       "         [ 7.],\n",
       "         [ 8.],\n",
       "         [ 9.],\n",
       "         [10.]], device='mps:0'),\n",
       " tensor([ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.], device='mps:0'),\n",
       " torch.Size([10]))"
      ]
     },
     "execution_count": 647,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_unsqueezed = torch.arange(1., 11.).reshape(10, 1)\n",
    "x_squeezed = torch.squeeze(x_unsqueezed)\n",
    "x_unsqueezed, x_squeezed, x_squeezed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 648,
   "id": "c692c564-5664-4e69-a578-981db4fbbe39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.], device='mps:0'),\n",
       " tensor([[ 1.],\n",
       "         [ 2.],\n",
       "         [ 3.],\n",
       "         [ 4.],\n",
       "         [ 5.],\n",
       "         [ 6.],\n",
       "         [ 7.],\n",
       "         [ 8.],\n",
       "         [ 9.],\n",
       "         [10.]], device='mps:0'),\n",
       " torch.Size([10, 1]))"
      ]
     },
     "execution_count": 648,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_unsqueezed = torch.unsqueeze(x_squeezed, dim=-1)\n",
    "x_squeezed, x_unsqueezed, x_unsqueezed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 649,
   "id": "438e2546-0b85-4cc8-8c1c-d7141902c6bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 1.],\n",
       "         [ 2.],\n",
       "         [ 3.],\n",
       "         [ 4.],\n",
       "         [ 5.],\n",
       "         [ 6.],\n",
       "         [ 7.],\n",
       "         [ 8.],\n",
       "         [ 9.],\n",
       "         [10.]], device='mps:0'),\n",
       " tensor([[ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.]], device='mps:0'),\n",
       " torch.Size([1, 10]))"
      ]
     },
     "execution_count": 649,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_permuted = torch.permute(x_unsqueezed, dims=(1, 0))\n",
    "x_unsqueezed, x_permuted, x_permuted.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 650,
   "id": "80e453d6-3dbf-406f-9c7e-93877e3b75db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([224, 224, 3]), torch.Size([3, 224, 224]))"
      ]
     },
     "execution_count": 650,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# permute is useful for Computer Vision\n",
    "image = torch.rand(224, 224, 3)\n",
    "\n",
    "image_permuted = image.permute(2, 0, 1)\n",
    "\n",
    "image.shape, image_permuted.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5901b55d-8acc-444e-a8b0-610c878004d6",
   "metadata": {},
   "source": [
    "## Tensor Access Patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 651,
   "id": "6c1f7206-459d-4c68-bb46-8172ac746f3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[1, 2, 3],\n",
       "          [4, 5, 6],\n",
       "          [7, 8, 9]]], device='mps:0'),\n",
       " torch.Size([1, 3, 3]))"
      ]
     },
     "execution_count": 651,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Indexing\n",
    "\n",
    "x = torch.arange(1, 10).reshape(1, 3, 3)\n",
    "x, x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 652,
   "id": "52dacc0e-1022-442a-9faf-e77ebfff8487",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1, 2, 3],\n",
       "         [4, 5, 6],\n",
       "         [7, 8, 9]], device='mps:0'),\n",
       " torch.Size([3, 3]))"
      ]
     },
     "execution_count": 652,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0], x[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 653,
   "id": "6d2a96f0-a560-42d2-a822-9dbc93f4dcf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1, 2, 3]], device='mps:0'), torch.Size([1, 3]))"
      ]
     },
     "execution_count": 653,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:, 0], x[:, 0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 654,
   "id": "2c31a2bc-d3c2-4480-b298-c2f8b6c63a5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1, 2, 3], device='mps:0'), torch.Size([3]))"
      ]
     },
     "execution_count": 654,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0, 0], x[0, 0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 655,
   "id": "964bf00e-4c88-4985-b761-6ad7a0cc1d90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1, device='mps:0')"
      ]
     },
     "execution_count": 655,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 656,
   "id": "34973074-9c4a-4a8c-8113-94d28a8e45a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2, device='mps:0')"
      ]
     },
     "execution_count": 656,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0, 0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 657,
   "id": "3fb67fc9-9ec0-4388-a352-58dffbd0b376",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4, device='mps:0')"
      ]
     },
     "execution_count": 657,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0, 1, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 658,
   "id": "6aa73875-58d3-45b7-b23f-33b765b2b678",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3]], device='mps:0')"
      ]
     },
     "execution_count": 658,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:, 0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 659,
   "id": "b3308fce-6b26-4d46-bd6e-614652eee47c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 4, 7]], device='mps:0')"
      ]
     },
     "execution_count": 659,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:, :, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35196701-a33c-4502-b1fc-92b18897eb51",
   "metadata": {},
   "source": [
    "## Interacting with NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 660,
   "id": "8d1f22d2-6fa1-423d-95c6-6244f49f8898",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1., 2., 3., 4., 5., 6., 7.]),\n",
       " (7,),\n",
       " tensor([1., 2., 3., 4., 5., 6., 7.], dtype=torch.float64),\n",
       " torch.Size([7]))"
      ]
     },
     "execution_count": 660,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# From NumPy\n",
    "\n",
    "array = np.arange(1., 8.)\n",
    "tensor = torch.from_numpy(array)\n",
    "\n",
    "# .from_numpy will convert to float64!\n",
    "# array and tensor SHARE MEMORY!\n",
    "\n",
    "array, array.shape, tensor, tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 661,
   "id": "2b8a7539-82b0-4b16-b942-96f7c1f7da9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([11., 12., 13., 14., 15., 16., 17.]),\n",
       " tensor([11., 12., 13., 14., 15., 16., 17.], dtype=torch.float64))"
      ]
     },
     "execution_count": 661,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array += 10\n",
    "\n",
    "array, tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 662,
   "id": "0440e1ef-f481-4ee5-986b-57334aff3379",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1., 2., 3., 4., 5., 6., 7.]),\n",
       " tensor([1., 2., 3., 4., 5., 6., 7.], dtype=torch.float64))"
      ]
     },
     "execution_count": 662,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor -= 10\n",
    "\n",
    "array, tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 663,
   "id": "f5e247b6-9220-4542-ac13-eaf500f12aa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 1., 1., 1., 1., 1., 1.], device='mps:0'),\n",
       " torch.Size([7]),\n",
       " array([1., 1., 1., 1., 1., 1., 1.], dtype=float32),\n",
       " (7,))"
      ]
     },
     "execution_count": 663,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To NumPy\n",
    "\n",
    "tensor = torch.ones(7)\n",
    "numpy_tensor = tensor.cpu().numpy()\n",
    "\n",
    "# If the tensor is on GPU, call .cpu() before .numpy()\n",
    "# .numpy will convert to float32!\n",
    "\n",
    "tensor, tensor.shape, numpy_tensor, numpy_tensor.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb34574-07c2-43de-9d26-7b8a945a1ecd",
   "metadata": {},
   "source": [
    "# Reproducibility in PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 664,
   "id": "7a4ba36e-1dd3-4902-825c-c45f9885afee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[8.1718e-01, 5.8811e-01, 5.5805e-01, 7.6914e-01],\n",
       "         [3.3936e-01, 4.5596e-01, 6.7508e-01, 4.4060e-04],\n",
       "         [4.0876e-01, 1.7912e-01, 5.9732e-01, 8.4722e-01]], device='mps:0'),\n",
       " tensor([[0.0661, 0.3270, 0.5155, 0.2259],\n",
       "         [0.8333, 0.5891, 0.2452, 0.5659],\n",
       "         [0.4646, 0.4861, 0.5399, 0.6836]], device='mps:0'),\n",
       " tensor([[False, False, False, False],\n",
       "         [False, False, False, False],\n",
       "         [False, False, False, False]], device='mps:0'))"
      ]
     },
     "execution_count": 664,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RANDOM_SEED = 42\n",
    "\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "\n",
    "random_tensor_A = torch.rand(3, 4)\n",
    "random_tensor_B = torch.rand(3, 4)\n",
    "\n",
    "random_tensor_A, random_tensor_B, random_tensor_A == random_tensor_B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 665,
   "id": "b62a32be-8285-4ca3-a34b-324dc95f6c75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[True, True, True, True],\n",
       "         [True, True, True, True],\n",
       "         [True, True, True, True]], device='mps:0'),\n",
       " tensor([[True, True, True, True],\n",
       "         [True, True, True, True],\n",
       "         [True, True, True, True]], device='mps:0'))"
      ]
     },
     "execution_count": 665,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(RANDOM_SEED)\n",
    "\n",
    "random_tensor_A = torch.rand(3, 4)\n",
    "random_tensor_C = torch.rand(3, 4)\n",
    "\n",
    "\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "\n",
    "random_tensor_B = torch.rand(3, 4)\n",
    "random_tensor_D = torch.rand(3, 4)\n",
    "\n",
    "\n",
    "random_tensor_A == random_tensor_B, random_tensor_C == random_tensor_D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e12b932-6ea5-463d-9088-dd2d799e3d8c",
   "metadata": {},
   "source": [
    "# PyTorch on GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 666,
   "id": "0c84b36e-fe83-43c1-bffa-2c5fcc6c5b43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(False, False)"
      ]
     },
     "execution_count": 666,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for GPU access\n",
    "\n",
    "torch.cuda.is_available(), torch.backends.cuda.is_built()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 667,
   "id": "1b9c893b-209e-4302-8074-2d02f0e260a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, True)"
      ]
     },
     "execution_count": 667,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.backends.mps.is_available(), torch.backends.mps.is_built()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 668,
   "id": "bde50ceb-b36a-461f-a546-eb79f50fd010",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 668,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.backends.cudnn.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 669,
   "id": "1dc1f656-6b93-4949-98bd-eb1ac322b865",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mps'"
      ]
     },
     "execution_count": 669,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Device Agnostic Code\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() \\\n",
    "    else \"mps\" if torch.backends.mps.is_available() \\\n",
    "    else \"cpu\"\n",
    "\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 670,
   "id": "58d06d7a-814c-4e89-9cb9-3e0dbdb872a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 670,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count number of CUDA GPUs\n",
    "\n",
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 671,
   "id": "69d6a45c-1fe1-4320-accd-85fc0d5c82dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1, 2, 3]), device(type='cpu'))"
      ]
     },
     "execution_count": 671,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Putting tensors and models on the GPU\n",
    "\n",
    "tensor = torch.tensor([1, 2, 3], device=\"cpu\")\n",
    "\n",
    "tensor, tensor.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 672,
   "id": "6cf47169-1010-4ae0-8e6c-6580a45de55a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1, 2, 3], device='mps:0'), device(type='mps', index=0))"
      ]
     },
     "execution_count": 672,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Move to GPU if available\n",
    "\n",
    "tensor_on_gpu = tensor.to(DEVICE)\n",
    "\n",
    "tensor_on_gpu, tensor_on_gpu.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 673,
   "id": "d508681c-38af-4028-a6d3-cc8a2ae775fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3])"
      ]
     },
     "execution_count": 673,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Back to CPU\n",
    "\n",
    "tensor_on_gpu.cpu().numpy()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
